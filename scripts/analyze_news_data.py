#!/usr/bin/env python3
"""
ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã¨å“è³ªåˆ†æ
"""

import json
import pandas as pd
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import sys
import os

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database import DatabaseManager

class NewsDataAnalyzer:
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿åˆ†æå™¨"""
    
    def __init__(self, config_path: str = "../config.json"):
        """åˆæœŸåŒ–"""
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        self.db_manager = DatabaseManager(config["database"])
    
    def get_news_dataframe(self, days: int = 30) -> pd.DataFrame:
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã¨ã—ã¦å–å¾—"""
        news_data = self.db_manager.get_recent_news(days=days, limit=5000)
        return pd.DataFrame(news_data)
    
    def analyze_collection_stats(self, days: int = 30) -> dict:
        """åé›†çµ±è¨ˆåˆ†æ"""
        try:
            with self.db_manager.get_connection() as conn:
                if self.db_manager.db_type == "postgresql":
                    sql = """
                        SELECT 
                            DATE(collection_date) as date,
                            SUM(total_collected) as daily_collected,
                            AVG(execution_time_seconds) as avg_execution_time,
                            SUM(api_calls_made) as daily_api_calls,
                            SUM(high_priority_count) as high_priority,
                            SUM(medium_priority_count) as medium_priority,
                            SUM(low_priority_count) as low_priority
                        FROM collection_stats 
                        WHERE collection_date >= NOW() - INTERVAL '%s days'
                        GROUP BY DATE(collection_date)
                        ORDER BY date DESC
                    """
                    cursor = conn.cursor()
                    cursor.execute(sql, (days,))
                else:
                    sql = """
                        SELECT 
                            CAST(collection_date AS DATE) as date,
                            SUM(total_collected) as daily_collected,
                            AVG(execution_time_seconds) as avg_execution_time,
                            SUM(api_calls_made) as daily_api_calls,
                            SUM(high_priority_count) as high_priority,
                            SUM(medium_priority_count) as medium_priority,
                            SUM(low_priority_count) as low_priority
                        FROM collection_stats 
                        WHERE collection_date >= DATEADD(day, -?, GETDATE())
                        GROUP BY CAST(collection_date AS DATE)
                        ORDER BY date DESC
                    """
                    cursor = conn.cursor()
                    cursor.execute(sql, (days,))
                
                results = cursor.fetchall()
                return pd.DataFrame(results, columns=[
                    'date', 'daily_collected', 'avg_execution_time', 'daily_api_calls',
                    'high_priority', 'medium_priority', 'low_priority'
                ])
                
        except Exception as e:
            print(f"çµ±è¨ˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def generate_report(self, days: int = 30) -> str:
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = []
        report.append("=" * 60)
        report.append("NewsCollector ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        report.append("=" * 60)
        report.append(f"åˆ†ææœŸé–“: éå»{days}æ—¥é–“")
        report.append(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿åˆ†æ
        df = self.get_news_dataframe(days)
        if not df.empty:
            report.append("ğŸ“Š ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼")
            report.append("-" * 30)
            report.append(f"ç·ãƒ‹ãƒ¥ãƒ¼ã‚¹ä»¶æ•°: {len(df):,} ä»¶")
            report.append(f"ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚½ãƒ¼ã‚¹æ•°: {df['source'].nunique()} ç¤¾")
            report.append(f"å¹³å‡å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢: {df['priority_score'].mean():.1f}")
            report.append(f"é«˜å„ªå…ˆåº¦ãƒ‹ãƒ¥ãƒ¼ã‚¹: {len(df[df['priority_score'] >= 25])} ä»¶")
            report.append("")
            
            # ã‚½ãƒ¼ã‚¹åˆ¥çµ±è¨ˆ
            report.append("ğŸ“° ã‚½ãƒ¼ã‚¹åˆ¥çµ±è¨ˆ (Top 10)")
            report.append("-" * 30)
            source_counts = df['source'].value_counts().head(10)
            for source, count in source_counts.items():
                report.append(f"  {source}: {count} ä»¶")
            report.append("")
            
            # é‡‘å±ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
            if 'metal_category' in df.columns:
                report.append("ğŸ”© é‡‘å±ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ")
                report.append("-" * 30)
                metal_counts = df['metal_category'].value_counts()
                for metal, count in metal_counts.items():
                    report.append(f"  {metal}: {count} ä»¶")
                report.append("")
            
            # å„ªå…ˆåº¦åˆ†å¸ƒ
            report.append("â­ å„ªå…ˆåº¦åˆ†å¸ƒ")
            report.append("-" * 30)
            high_priority = len(df[df['priority_score'] >= 25])
            medium_priority = len(df[(df['priority_score'] >= 15) & (df['priority_score'] < 25)])
            low_priority = len(df[df['priority_score'] < 15])
            report.append(f"  é«˜å„ªå…ˆåº¦ (25+): {high_priority} ä»¶ ({high_priority/len(df)*100:.1f}%)")
            report.append(f"  ä¸­å„ªå…ˆåº¦ (15-24): {medium_priority} ä»¶ ({medium_priority/len(df)*100:.1f}%)")
            report.append(f"  ä½å„ªå…ˆåº¦ (<15): {low_priority} ä»¶ ({low_priority/len(df)*100:.1f}%)")
            report.append("")
        
        # åé›†çµ±è¨ˆåˆ†æ
        stats_df = self.analyze_collection_stats(days)
        if not stats_df.empty:
            report.append("ğŸ“ˆ åé›†ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
            report.append("-" * 30)
            report.append(f"ç·åé›†å®Ÿè¡Œå›æ•°: {len(stats_df)} å›")
            report.append(f"å¹³å‡å®Ÿè¡Œæ™‚é–“: {stats_df['avg_execution_time'].mean():.1f} ç§’")
            report.append(f"1æ—¥ã‚ãŸã‚Šå¹³å‡åé›†æ•°: {stats_df['daily_collected'].mean():.1f} ä»¶")
            report.append(f"1æ—¥ã‚ãŸã‚ŠAPIå‘¼ã³å‡ºã—: {stats_df['daily_api_calls'].mean():.1f} å›")
            report.append("")
            
            # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°
            if len(stats_df) > 0:
                latest = stats_df.iloc[0]
                report.append("ğŸ“… æœ€æ–°åé›†çµæœ")
                report.append("-" * 30)
                report.append(f"  æ—¥ä»˜: {latest['date']}")
                report.append(f"  åé›†ä»¶æ•°: {latest['daily_collected']} ä»¶")
                report.append(f"  å®Ÿè¡Œæ™‚é–“: {latest['avg_execution_time']:.1f} ç§’")
                report.append(f"  é«˜å„ªå…ˆåº¦: {latest['high_priority']} ä»¶")
                report.append(f"  ä¸­å„ªå…ˆåº¦: {latest['medium_priority']} ä»¶")
                report.append(f"  ä½å„ªå…ˆåº¦: {latest['low_priority']} ä»¶")
                report.append("")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçŠ¶æ³
        report.append("ğŸ”— ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³")
        report.append("-" * 30)
        if self.db_manager.test_connection():
            report.append("  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: âœ… æ­£å¸¸")
        else:
            report.append("  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: âŒ ã‚¨ãƒ©ãƒ¼")
        
        report.append(f"  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—: {self.db_manager.db_type.upper()}")
        report.append("")
        
        report.append("=" * 60)
        
        return "\n".join(report)
    
    def export_high_priority_news(self, days: int = 7, min_score: int = 25) -> str:
        """é«˜å„ªå…ˆåº¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        df = self.get_news_dataframe(days)
        
        if df.empty:
            return "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
        
        high_priority = df[df['priority_score'] >= min_score].copy()
        high_priority = high_priority.sort_values('priority_score', ascending=False)
        
        # CSVå‡ºåŠ›
        filename = f"high_priority_news_{datetime.now().strftime('%Y%m%d')}.csv"
        high_priority.to_csv(filename, index=False, encoding='utf-8-sig')
        
        return f"é«˜å„ªå…ˆåº¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ {len(high_priority)} ä»¶ã‚’ {filename} ã«å‡ºåŠ›ã—ã¾ã—ãŸ"

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    try:
        analyzer = NewsDataAnalyzer()
        
        # åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = analyzer.generate_report(days=30)
        print(report)
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        report_filename = f"news_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ {report_filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        # é«˜å„ªå…ˆåº¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        export_result = analyzer.export_high_priority_news(days=7, min_score=25)
        print(f"ğŸ“‹ {export_result}")
        
    except Exception as e:
        print(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()